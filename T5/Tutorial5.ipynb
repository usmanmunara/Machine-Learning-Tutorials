{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4487 - Tutorial 5: Predicting Popularity of Online News\n",
    "\n",
    "In this tutorial you will train regression models to predict the number of \"shares\" of a news article on Mashable.\n",
    "\n",
    "First we need to initialize Python.  Run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import IPython.core.display         \n",
    "# setup output image format (Chrome works best)\n",
    "# IPython.core.display.set_matplotlib_formats(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import string\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data and Pre-processing\n",
    "Next we need to load the data. **Unzip** `OnlineNewsPopularity.zip` in the same directory as this ipynb file.  Then run the following cell to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6608, 58)\n",
      "(6608,)\n"
     ]
    }
   ],
   "source": [
    "filename = 'OnlineNewsPopularity/OnlineNewsPopularity.csv'\n",
    "\n",
    "# read the data\n",
    "allfeatnames = []\n",
    "textdata      = []\n",
    "with open(filename, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        if len(allfeatnames)==0:\n",
    "            allfeatnames = row\n",
    "        else:\n",
    "            textdata.append(row)\n",
    "\n",
    "# put the data into a np array\n",
    "dataX = empty((len(textdata), len(allfeatnames)-3))\n",
    "dataY = empty(len(textdata))\n",
    "for i,row in enumerate(textdata):\n",
    "    # extract features (remove the first 2 features and the last feature)\n",
    "    dataX[i,:] = array([float(x) for x in row[2:-1]])\n",
    "    # extract target (last entry)\n",
    "    dataY[i] = float(row[-1])\n",
    "    \n",
    "# extract feature names\n",
    "featnames = [x.strip() for x in allfeatnames[2:-1]]\n",
    "\n",
    "# extract a subset of data\n",
    "dataX = dataX[::6]\n",
    "dataY = dataY[::6]\n",
    "\n",
    "print(dataX.shape)\n",
    "print(dataY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 58 features for each article.  Here are the feature names, and an example entry.  The actual description of the features can be found in the `OnlineNewsPopularity-features.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n_tokens_title', 'n_tokens_content', 'n_unique_tokens', 'n_non_stop_words', 'n_non_stop_unique_tokens', 'num_hrefs', 'num_self_hrefs', 'num_imgs', 'num_videos', 'average_token_length', 'num_keywords', 'data_channel_is_lifestyle', 'data_channel_is_entertainment', 'data_channel_is_bus', 'data_channel_is_socmed', 'data_channel_is_tech', 'data_channel_is_world', 'kw_min_min', 'kw_max_min', 'kw_avg_min', 'kw_min_max', 'kw_max_max', 'kw_avg_max', 'kw_min_avg', 'kw_max_avg', 'kw_avg_avg', 'self_reference_min_shares', 'self_reference_max_shares', 'self_reference_avg_sharess', 'weekday_is_monday', 'weekday_is_tuesday', 'weekday_is_wednesday', 'weekday_is_thursday', 'weekday_is_friday', 'weekday_is_saturday', 'weekday_is_sunday', 'is_weekend', 'LDA_00', 'LDA_01', 'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity', 'global_sentiment_polarity', 'global_rate_positive_words', 'global_rate_negative_words', 'rate_positive_words', 'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity', 'max_positive_polarity', 'avg_negative_polarity', 'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity', 'title_sentiment_polarity', 'abs_title_subjectivity', 'abs_title_sentiment_polarity']\n",
      "--- example article features---\n",
      "[ 1.20000000e+01  2.19000000e+02  6.63594467e-01  9.99999992e-01\n",
      "  8.15384609e-01  4.00000000e+00  2.00000000e+00  1.00000000e+00\n",
      "  0.00000000e+00  4.68036530e+00  5.00000000e+00  0.00000000e+00\n",
      "  1.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  4.96000000e+02  4.96000000e+02\n",
      "  4.96000000e+02  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  5.00331204e-01  3.78278930e-01  4.00046751e-02\n",
      "  4.12626477e-02  4.01225435e-02  5.21617145e-01  9.25619835e-02\n",
      "  4.56621005e-02  1.36986301e-02  7.69230769e-01  2.30769231e-01\n",
      "  3.78636364e-01  1.00000000e-01  7.00000000e-01 -3.50000000e-01\n",
      " -6.00000000e-01 -2.00000000e-01  5.00000000e-01 -1.87500000e-01\n",
      "  0.00000000e+00  1.87500000e-01]\n",
      "--- example article target (# of shares)\n",
      "593.0\n"
     ]
    }
   ],
   "source": [
    "print(featnames)\n",
    "\n",
    "print(\"--- example article features---\")\n",
    "print(dataX[0])\n",
    "print(\"--- example article target (# of shares)\")\n",
    "print(dataY[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now separate the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3304, 58)\n",
      "(3304, 58)\n"
     ]
    }
   ],
   "source": [
    "# randomly split data into 50% train and 50% test set\n",
    "trainX, testX, trainYo, testYo = \\\n",
    "  model_selection.train_test_split(dataX, dataY, \n",
    "  train_size=0.50, test_size=0.50, random_state=4487)\n",
    "\n",
    "print(trainX.shape)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we normalize the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize feature values\n",
    "# this makes comparing weights more meaningful\n",
    "scaler = preprocessing.StandardScaler()  \n",
    "trainXn = scaler.fit_transform(trainX)  \n",
    "testXn  = scaler.transform(testX)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the target value (number of shares) has a large dynamic range, we will transform the target values through the log function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# map targets to log-space\n",
    "%matplotlib inline\n",
    "trainY = log10(trainYo)\n",
    "testY  = log10(testYo)\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(trainYo, 25);\n",
    "plt.title('histogram of Y values')\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(trainY, 25);\n",
    "plt.title(\"histogram of log(Y) values\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prediction with Linear Regression\n",
    "\n",
    "First we will look at predicting the number of shares using simple linear regression models.  Use the training data to fit a linear model using Ordinary Least Squares and Ridge Regression.  Use cross-validation on the training set to select the optimal $\\alpha$ parameter for ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### INSERT YOUR CODE HERE\n",
    "## HINT: \n",
    "# 1. Ordinary Least Squares: linear_model.LinearRegression()\n",
    "# 2. Ridge Regression: linear_model.Ridge(alphas= )\n",
    "# 3. Rigge Regression with Cross-validation: linear_model.Ridge(alphas= )\n",
    "\n",
    "ols = linear_model.LinearRegression()\n",
    "ols.fit(trainXn, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha:  385.6620421163472\n",
      "train error:  0.28859917591560874\n",
      "test error :  0.2854267347255127\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "alphas = logspace(-5,15,30)\n",
    "\n",
    "trainAEs = empty(len(alphas))\n",
    "testAEs  = empty(len(alphas))\n",
    "for i,a in enumerate(alphas):\n",
    "    rr = linear_model.Ridge(alpha=a)\n",
    "    rr.fit(trainXn, trainY)\n",
    "    \n",
    "    trainAEs[i] = metrics.mean_absolute_error(trainY, rr.predict(trainXn))\n",
    "    testAEs[i]  = metrics.mean_absolute_error(testY, rr.predict(testXn))\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.semilogx(alphas, trainAEs)\n",
    "plt.xlabel('alpha')\n",
    "plt.title('train AE')\n",
    "plt.grid(True)\n",
    "plt.subplot(1,2,2)\n",
    "plt.semilogx(alphas, testAEs)\n",
    "plt.xlabel('alpha')\n",
    "plt.title('test AE')\n",
    "plt.grid(True)\n",
    "    \n",
    "rr = linear_model.RidgeCV(alphas=alphas, cv=5)\n",
    "rr.fit(trainXn, trainY)\n",
    "\n",
    "print(\"best alpha: \", rr.alpha_)\n",
    "\n",
    "trainAE = metrics.mean_absolute_error(trainY, rr.predict(trainXn))\n",
    "testAE  = metrics.mean_absolute_error(testY,  rr.predict(testXn))\n",
    "\n",
    "print(\"train error: \", trainAE)\n",
    "print(\"test error : \", testAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the two models using the _average absolute error_ (AE) between the predictions and the true values.  Below is  code that will calculate AE for the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS: train error = 0.2868817923560834\n",
      "OLS: test error = 189.21018338870027\n"
     ]
    }
   ],
   "source": [
    "# ols is the linear regression model\n",
    "trainAE = metrics.mean_absolute_error(trainY, ols.predict(trainXn))\n",
    "testAE  = metrics.mean_absolute_error(testY, ols.predict(testXn))\n",
    "print(\"OLS: train error =\", trainAE)\n",
    "print(\"OLS: test error =\", testAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RR: train error = 0.28859917591560874\n",
      "RR: test error = 0.2854267347255127\n"
     ]
    }
   ],
   "source": [
    "# rr is the ridge regression model\n",
    "trainAE = metrics.mean_absolute_error(trainY, rr.predict(trainXn))\n",
    "testAE  = metrics.mean_absolute_error(testY, rr.predict(testXn))\n",
    "print(\"RR: train error =\", trainAE)\n",
    "print(\"RR: test error =\", testAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model has better prediction ability on the test set? Why?\n",
    "- **Ridge Regression has better prediction ability as the alpha is selected using cross validation which helps helps reduce over-fitting by using a penalty term. On the other hand Linear regression classifier is over-fitting on this data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Which features are important?\n",
    "Next we will investigate which features are the most important for the prediction.  Use LASSO with cross-validation to learn the model, and print the training and testing error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAE: 0.28966720935858153\n",
      "Test MAE: 311.24310731944894\n"
     ]
    }
   ],
   "source": [
    "### INSERT YOUR CODE HERE\n",
    "## HINT\n",
    "# 1. LASSO with Cross-validation: linear_model.LassoCV()\n",
    "\n",
    "las = linear_model.LassoCV(alphas = logspace(-5,15,30))\n",
    "las.fit(trainXn, trainY)\n",
    "\n",
    "predTrain = las.predict(trainXn)\n",
    "predTest = las.predict(testX)\n",
    "testLoss = metrics.mean_absolute_error(testY, predTest)\n",
    "trainingLoss = metrics.mean_absolute_error(trainY, predTrain)\n",
    "\n",
    "print(\"Training MAE: {}\".format(trainingLoss))\n",
    "print(\"Test MAE: {}\".format(testLoss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the LASSO coefficients by sorting them in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : feature description\n",
      " 0.080 : kw_avg_avg\n",
      "-0.043 : LDA_02\n",
      "-0.033 : data_channel_is_entertainment\n",
      "-0.026 : average_token_length\n",
      "-0.026 : kw_max_avg\n",
      " 0.024 : num_hrefs\n",
      " 0.022 : kw_min_min\n",
      " 0.022 : is_weekend\n",
      " 0.022 : global_subjectivity\n",
      " 0.019 : data_channel_is_socmed\n",
      " 0.018 : self_reference_avg_sharess\n",
      "-0.018 : data_channel_is_bus\n",
      " 0.017 : n_tokens_content\n",
      "-0.016 : kw_avg_min\n",
      " 0.013 : LDA_00\n",
      " 0.011 : title_sentiment_polarity\n",
      "-0.009 : data_channel_is_lifestyle\n",
      "-0.009 : max_positive_polarity\n",
      " 0.008 : weekday_is_sunday\n",
      "-0.008 : avg_negative_polarity\n",
      "-0.007 : LDA_01\n",
      " 0.006 : num_keywords\n",
      "-0.005 : kw_min_max\n",
      " 0.005 : n_tokens_title\n",
      "-0.004 : weekday_is_friday\n",
      " 0.004 : weekday_is_monday\n",
      " 0.003 : self_reference_max_shares\n",
      " 0.003 : LDA_03\n",
      "-0.003 : weekday_is_tuesday\n",
      " 0.002 : data_channel_is_tech\n",
      " 0.002 : num_imgs\n",
      "-0.001 : kw_avg_max\n",
      "-0.001 : min_positive_polarity\n",
      "-0.001 : rate_positive_words\n",
      "-0.000 : num_self_hrefs\n",
      " 0.000 : num_videos\n",
      "-0.000 : avg_positive_polarity\n",
      "-0.000 : min_negative_polarity\n",
      "-0.000 : max_negative_polarity\n",
      "-0.000 : n_non_stop_unique_tokens\n",
      "-0.000 : n_non_stop_words\n",
      "-0.000 : n_unique_tokens\n",
      " 0.000 : title_subjectivity\n",
      " 0.000 : rate_negative_words\n",
      "-0.000 : data_channel_is_world\n",
      " 0.000 : global_rate_negative_words\n",
      " 0.000 : weekday_is_thursday\n",
      "-0.000 : global_rate_positive_words\n",
      "-0.000 : kw_max_min\n",
      "-0.000 : global_sentiment_polarity\n",
      "-0.000 : LDA_04\n",
      "-0.000 : kw_max_max\n",
      " 0.000 : kw_min_avg\n",
      " 0.000 : weekday_is_saturday\n",
      " 0.000 : self_reference_min_shares\n",
      " 0.000 : abs_title_subjectivity\n",
      "-0.000 : weekday_is_wednesday\n",
      " 0.000 : abs_title_sentiment_polarity\n"
     ]
    }
   ],
   "source": [
    "# sort coefficients from smallest to largest, then reverse it\n",
    "inds = argsort(abs(las.coef_))[::-1]\n",
    "# print out\n",
    "print(\"weight : feature description\")\n",
    "for i in inds:\n",
    "    print(\"{: .3f} : {}\".format(las.coef_[i], featnames[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Which features are most important for predicting the number of shares?  For these features, which feature values (low or high values) will yield a higher number of shares?_\n",
    "- **kw_avg_avg : High value of this feature will result in higher number of shares**\n",
    "- **LDA_02 : Low value of this feature will result in higher number of shares**\n",
    "- **kw_max_avg : Low value of this feature will result in higher number of shares**\n",
    "- **data_channel_is_entertainment : Low value of this feature will result in higher number of shares**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Kernel Methods and Support Vector Regression \n",
    "Next, let us try some non-linear regression model such as[ kernel ridge regression](https://scikit-learn.org/stable/modules/kernel_ridge.html), [random forest regression](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)(Optional), [support vector regression](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html). To improve the prediction accuracy in Tutorial 4, and using cross-validation on the training set to select the parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   40.8s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.0min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-ea0d711a2d0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mclfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmethodName\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'paramgrid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mclfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmethodName\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainXn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mpredTrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmethodName\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclfs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmethodName\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainXn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### INSERT YOUR CODE HERE\n",
    "##Hint: \n",
    "## 1. Kernel Ridge Regression:  kernel_ridge.KernelRidge(kernel='rbf'/'poly')\n",
    "## 2. Random Forest Regression: ensemble.RandomForestRegressor(random_state= , n_estimators= )\n",
    "## 3. Support Vector Regression: svm.SVR(kernel='poly')\n",
    "## 4. Avoid using large values of $C$ with SVR.\n",
    "\n",
    "\n",
    "methods = [\n",
    "    {'name': 'krr-rbf',\n",
    "     'clf': kernel_ridge.KernelRidge(kernel='rbf'),\n",
    "     'paramgrid': {'alpha': logspace(-3,3,10), 'gamma': logspace(-6,3,10)}\n",
    "    }, \n",
    "    {'name': 'rf',\n",
    "     'clf': ensemble.RandomForestRegressor(random_state=4487, n_estimators=100),\n",
    "     'paramgrid': {'max_depth': array([1, 2, 3, 4, 5, 10, 15])}\n",
    "    }, \n",
    "    {'name': 'svr-poly',\n",
    "     'clf': svm.SVR(kernel='poly'),\n",
    "     'paramgrid':  {'C': logspace(-3,0,5), 'degree': [1,2], 'epsilon': logspace(-2,2,5)}\n",
    "    }, \n",
    "]\n",
    "\n",
    "clfs = {}\n",
    "\n",
    "predTrain = {}\n",
    "predTest = {}\n",
    "\n",
    "trainAE = {}\n",
    "testAE = {}\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    methodName = method['name']\n",
    "    \n",
    "    clfs[methodName] = model_selection.GridSearchCV(method['clf'], param_grid=method['paramgrid'], cv=5, verbose=1, n_jobs=-1)\n",
    "    clfs[methodName].fit(trainXn, trainY)\n",
    "    \n",
    "    predTrain[methodName] = clfs[methodName].predict(trainXn)\n",
    "    predTest[methodName] = clfs[methodName].predict(testXn)\n",
    "    \n",
    "    trainAE[methodName] = metrics.mean_absolute_error(trainY, predTrain[methodName])\n",
    "    testAE[methodName]  = metrics.mean_absolute_error(testY, predTest[methodName])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in trainAE:\n",
    "    print(\"Training MAE - \"+ key + \": \" + str(trainAE[key]))\n",
    "    \n",
    "for key in testAE:\n",
    "    print(\"Testing MAE - \"+ key + \": \" + str(testAE[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      ".............................................................................................................................................................................................................................................................................................................................C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.637885813098052, tolerance: 4.468952155620218\n",
      "  tol, rng, random, positive)\n",
      "........C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.6517537897998125, tolerance: 4.468952155620218\n",
      "  tol, rng, random, positive)\n",
      "..C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.561081759353698, tolerance: 4.6517788077229305\n",
      "  tol, rng, random, positive)\n",
      ".....C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.59721667795057, tolerance: 4.6517788077229305\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.705016783970393, tolerance: 4.468952155620218\n",
      "  tol, rng, random, positive)\n",
      "....C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.649998866300109, tolerance: 4.6517788077229305\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.78317553357013, tolerance: 4.468952155620218\n",
      "  tol, rng, random, positive)\n",
      "..C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.886801889806264, tolerance: 4.535620050982014\n",
      "  tol, rng, random, positive)\n",
      "..C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.299833440418837, tolerance: 4.6517788077229305\n",
      "  tol, rng, random, positive)\n",
      "..C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.986443350782679, tolerance: 4.468952155620218\n",
      "  tol, rng, random, positive)\n",
      "..............C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.516945043445162, tolerance: 4.535620050982014\n",
      "  tol, rng, random, positive)\n",
      ".............................................C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.970403898156263, tolerance: 4.6517788077229305\n",
      "  tol, rng, random, positive)\n",
      ".....C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.141801960362415, tolerance: 4.468952155620218\n",
      "  tol, rng, random, positive)\n",
      "...C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.854919931915987, tolerance: 4.535620050982014\n",
      "  tol, rng, random, positive)\n",
      "..........C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.113043567604421, tolerance: 4.468952155620218\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.68406437233611, tolerance: 4.6517788077229305\n",
      "  tol, rng, random, positive)\n",
      ".....C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.697330775431624, tolerance: 4.535620050982014\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.737789096215408, tolerance: 4.468952155620218\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.250440677868994, tolerance: 4.6517788077229305\n",
      "  tol, rng, random, positive)\n",
      "...........C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.789007687121483, tolerance: 4.535620050982014\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.597340596366848, tolerance: 4.468952155620218\n",
      "  tol, rng, random, positive)\n",
      "..C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.128442032693357, tolerance: 4.589222750537921\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.663018608400563, tolerance: 4.535620050982014\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.041931101477871, tolerance: 4.468952155620218\n",
      "  tol, rng, random, positive)\n",
      "...C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.238761492226985, tolerance: 4.589222750537921\n",
      "  tol, rng, random, positive)\n",
      "..C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.078347411410647, tolerance: 4.535620050982014\n",
      "  tol, rng, random, positive)\n",
      "...C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.509896631817213, tolerance: 4.589222750537921\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.205706920128279, tolerance: 4.535620050982014\n",
      "  tol, rng, random, positive)\n",
      "..C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.028215138369234, tolerance: 4.589222750537921\n",
      "  tol, rng, random, positive)\n",
      "...C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.917926995750946, tolerance: 4.535620050982014\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.803970714039394, tolerance: 4.589222750537921\n",
      "  tol, rng, random, positive)\n",
      "....C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22.724337027348014, tolerance: 4.589222750537921\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.6261175838978374, tolerance: 4.535620050982014\n",
      "  tol, rng, random, positive)\n",
      "....C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.70287404106972, tolerance: 4.589222750537921\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.066902255753291, tolerance: 4.535620050982014\n",
      "  tol, rng, random, positive)\n",
      "..C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.793301260136445, tolerance: 4.589222750537921\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.7173600588384375, tolerance: 4.468952155620218\n",
      "  tol, rng, random, positive)\n",
      "..C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.820405784324493, tolerance: 4.535620050982014\n",
      "  tol, rng, random, positive)\n",
      "..C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.136543345940623, tolerance: 4.589222750537921\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.904898012999013, tolerance: 4.6517788077229305\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.20619434290117, tolerance: 4.535620050982014\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.0640419401930785, tolerance: 4.468952155620218\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.642189045422214, tolerance: 4.589222750537921\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.738047011086081, tolerance: 4.6517788077229305\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.319759248666742, tolerance: 4.589222750537921\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 12.124407211515177, tolerance: 4.535620050982014\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.53661474884953, tolerance: 4.6517788077229305\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.444018220788053, tolerance: 4.589222750537921\n",
      "  tol, rng, random, positive)\n",
      "..C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.354714227612249, tolerance: 4.535620050982014\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.42385837132656, tolerance: 4.589222750537921\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.094102377835071, tolerance: 4.6517788077229305\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.029139219619083, tolerance: 4.535620050982014\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.136651967620082, tolerance: 4.589222750537921\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.192416366584581, tolerance: 4.589222750537921\n",
      "  tol, rng, random, positive)\n",
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.200930558437449, tolerance: 4.589222750537921\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".C:\\Users\\Muhammad Usman\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7.686081580803204, tolerance: 4.589222750537921\n",
      "  tol, rng, random, positive)\n",
      ".....[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error: 0.2852662482810267\n",
      "test error : 0.2858450846165216\n"
     ]
    }
   ],
   "source": [
    "# LASSO - poly features\n",
    "polyfeats = preprocessing.PolynomialFeatures(degree=2)\n",
    "trainXnf  = polyfeats.fit_transform(trainXn)\n",
    "testXnf   = polyfeats.transform(testXn) \n",
    "\n",
    "myname = 'las-poly'\n",
    "clfs[myname] = linear_model.LassoCV(max_iter=2000, tol=1e-2, verbose=1, n_jobs=-1)\n",
    "clfs[myname].fit(trainXnf, trainY)\n",
    "trainAE[myname] = metrics.mean_absolute_error(trainY, clfs[myname].predict(trainXnf))\n",
    "testAE[myname]  = metrics.mean_absolute_error(testY, clfs[myname].predict(testXnf))\n",
    "\n",
    "print(\"train error:\", trainAE[myname])\n",
    "print(\"test error :\", testAE[myname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770\n",
      "weight : feature description\n",
      " 0.089 : kw_avg_avg(1) \n",
      " 0.018 : kw_min_avg(2) \n",
      "-0.015 : data_channel_is_entertainment(2) \n",
      "-0.011 : LDA_02(2) \n",
      " 0.009 : kw_min_min(2) \n",
      "-0.009 : data_channel_is_world(1) LDA_02(1) \n",
      " 0.008 : data_channel_is_socmed(1) LDA_00(1) \n",
      " 0.008 : weekday_is_sunday(2) \n",
      " 0.008 : global_subjectivity(1) \n",
      "-0.008 : data_channel_is_world(1) rate_negative_words(1) \n",
      " 0.007 : n_tokens_content(2) \n",
      "-0.006 : n_tokens_content(1) num_imgs(1) \n",
      "-0.006 : data_channel_is_lifestyle(1) max_positive_polarity(1) \n",
      "-0.006 : weekday_is_monday(1) title_sentiment_polarity(1) \n",
      " 0.006 : weekday_is_thursday(1) title_sentiment_polarity(1) \n",
      " 0.006 : num_videos(1) data_channel_is_bus(1) \n",
      " 0.006 : kw_max_avg(1) LDA_00(1) \n",
      " 0.006 : data_channel_is_tech(2) \n",
      " 0.006 : num_keywords(1) kw_avg_max(1) \n",
      "-0.005 : n_tokens_title(1) n_tokens_content(1) \n",
      "-0.005 : kw_max_max(1) title_sentiment_polarity(1) \n",
      " 0.005 : n_unique_tokens(1) rate_negative_words(1) \n",
      " 0.004 : num_hrefs(2) \n",
      " 0.004 : kw_avg_avg(1) LDA_00(1) \n",
      " 0.004 : data_channel_is_socmed(2) \n",
      " 0.004 : title_sentiment_polarity(1) abs_title_sentiment_polarity(1) \n",
      " 0.004 : weekday_is_saturday(2) \n",
      " 0.004 : n_tokens_content(1) num_hrefs(1) \n",
      "-0.003 : kw_max_avg(2) \n",
      "-0.003 : n_tokens_title(1) n_non_stop_words(1) \n",
      " 0.003 : LDA_00(1) global_rate_positive_words(1) \n",
      "-0.003 : num_imgs(1) data_channel_is_socmed(1) \n",
      " 0.003 : LDA_00(2) \n",
      "-0.003 : weekday_is_monday(1) global_rate_negative_words(1) \n",
      "-0.002 : data_channel_is_lifestyle(1) avg_positive_polarity(1) \n",
      " 0.002 : kw_min_avg(1) weekday_is_monday(1) \n",
      " 0.002 : weekday_is_friday(1) max_positive_polarity(1) \n",
      "-0.002 : kw_min_avg(1) kw_max_avg(1) \n",
      " 0.002 : kw_max_avg(1) self_reference_max_shares(1) \n",
      " 0.002 : LDA_03(1) rate_negative_words(1) \n",
      "-0.002 : num_hrefs(1) data_channel_is_socmed(1) \n",
      "-0.002 : num_self_hrefs(2) \n",
      "-0.002 : kw_min_avg(1) self_reference_max_shares(1) \n",
      "-0.002 : num_keywords(1) data_channel_is_tech(1) \n",
      " 0.001 : n_tokens_title(1) LDA_03(1) \n",
      "-0.001 : LDA_03(1) global_rate_positive_words(1) \n",
      "-0.001 : data_channel_is_lifestyle(2) \n",
      " 0.001 : global_sentiment_polarity(1) min_positive_polarity(1) \n",
      " 0.001 : weekday_is_monday(2) \n",
      "-0.001 : kw_avg_avg(1) is_weekend(1) \n",
      " 0.001 : num_imgs(1) min_positive_polarity(1) \n",
      "-0.001 : num_keywords(2) \n",
      "-0.001 : kw_avg_max(1) kw_min_avg(1) \n",
      " 0.001 : num_imgs(2) \n",
      "-0.001 : num_videos(1) kw_max_avg(1) \n"
     ]
    }
   ],
   "source": [
    "# sort coefficients from smallest to largest, then reverse it\n",
    "inds = argsort(abs(clfs['las-poly'].coef_))[::-1]\n",
    "print(len(polyfeats.powers_))\n",
    "# print out\n",
    "print(\"weight : feature description\")\n",
    "for i in inds:\n",
    "    if abs(clfs['las-poly'].coef_[i])>1e-3:\n",
    "        # get active features and powers\n",
    "        pows = where(polyfeats.powers_[i])[0]\n",
    "        fstr = \"\"\n",
    "        for p in pows:\n",
    "            fstr += featnames[p] + \"(\" + str(polyfeats.powers_[i][p]) + \") \"\n",
    "        print(\"{: .3f} : {}\".format(clfs['las-poly'].coef_[i], fstr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Which regression method performs the best? Why do you think so?_\n",
    "- **I think all the polynomial methods performed better as higher degree polynomial kernels allow a more flexible decision boundary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
